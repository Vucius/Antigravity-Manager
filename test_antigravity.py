#!/usr/bin/env python3
"""
Antigravity Tools API æµ‹è¯•è„šæœ¬
æµ‹è¯• OpenAI å…¼å®¹çš„ API ç«¯ç‚¹
"""

import openai
import sys

def test_basic_request():
    """æµ‹è¯•åŸºç¡€è¯·æ±‚"""
    print("=" * 60)
    print("æµ‹è¯• 1: åŸºç¡€è¯·æ±‚ï¼ˆéæµå¼ï¼‰")
    print("=" * 60)
    
    try:
        client = openai.OpenAI(
            api_key="sk-7fd8d437a64b4bf8b011fb17945a109d",
            base_url="http://127.0.0.1:8045/v1"
        )
        
        response = client.chat.completions.create(
            model="gemini-3-flash",
            messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}],
            max_tokens=100
        )
        
        print(f"âœ… è¯·æ±‚æˆåŠŸï¼")
        print(f"æ¨¡å‹: {response.model}")
        print(f"å›å¤: {response.choices[0].message.content}")
        print(f"Token ä½¿ç”¨: {response.usage.total_tokens if response.usage else 'N/A'}")
        return True
        
    except Exception as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return False

def test_streaming_request():
    """æµ‹è¯•æµå¼è¯·æ±‚"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æµå¼è¯·æ±‚")
    print("=" * 60)
    
    try:
        client = openai.OpenAI(
            api_key="sk-7fd8d437a64b4bf8b011fb17945a109d",
            base_url="http://127.0.0.1:8045/v1"
        )
        
        stream = client.chat.completions.create(
            model="gemini-3-flash",
            messages=[{"role": "user", "content": "æ•°åˆ°5"}],
            stream=True
        )
        
        print("âœ… æµå¼å“åº”å¼€å§‹:")
        print("å›å¤: ", end="", flush=True)
        
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="", flush=True)
        
        print("\nâœ… æµå¼è¯·æ±‚å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}")
        return False

def test_multi_turn():
    """æµ‹è¯•å¤šè½®å¯¹è¯"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: å¤šè½®å¯¹è¯")
    print("=" * 60)
    
    try:
        client = openai.OpenAI(
            api_key="sk-7fd8d437a64b4bf8b011fb17945a109d",
            base_url="http://127.0.0.1:8045/v1"
        )
        
        messages = [
            {"role": "user", "content": "æˆ‘çš„åå­—æ˜¯å°æ˜"},
            {"role": "assistant", "content": "ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚"},
            {"role": "user", "content": "æˆ‘åˆšæ‰è¯´æˆ‘å«ä»€ä¹ˆï¼Ÿ"}
        ]
        
        response = client.chat.completions.create(
            model="gemini-3-flash",
            messages=messages,
            max_tokens=50
        )
        
        print(f"âœ… å¤šè½®å¯¹è¯æˆåŠŸï¼")
        print(f"å›å¤: {response.choices[0].message.content}")
        return True
        
    except Exception as e:
        print(f"âŒ å¤šè½®å¯¹è¯å¤±è´¥: {e}")
        return False

def main():
    print("\nğŸš€ Antigravity Tools API æµ‹è¯•")
    print(f"API ç«¯ç‚¹: http://127.0.0.1:8045/v1")
    print(f"API å¯†é’¥: sk-7fd8d437a64b4bf8b011fb17945a109d")
    print()
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(("åŸºç¡€è¯·æ±‚", test_basic_request()))
    results.append(("æµå¼è¯·æ±‚", test_streaming_request()))
    results.append(("å¤šè½®å¯¹è¯", test_multi_turn()))
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{name}: {status}")
    
    total = len(results)
    passed = sum(1 for _, success in results if success)
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Antigravity ä»£ç†æœåŠ¡è¿è¡Œæ­£å¸¸ã€‚")
        sys.exit(0)
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Antigravity æœåŠ¡çŠ¶æ€ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()
